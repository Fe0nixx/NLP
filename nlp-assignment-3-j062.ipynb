{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-08-10T05:33:57.649282Z","iopub.status.busy":"2025-08-10T05:33:57.648986Z","iopub.status.idle":"2025-08-10T05:33:59.326504Z","shell.execute_reply":"2025-08-10T05:33:59.325685Z","shell.execute_reply.started":"2025-08-10T05:33:57.649250Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n"]}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    AutoTokenizer, AutoModelForSequenceClassification,\n    TrainingArguments, Trainer, EarlyStoppingCallback\n)\nfrom sklearn.metrics import f1_score, accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datasets import Dataset as HFDataset\nimport warnings\nimport os\nwarnings.filterwarnings('ignore')\n\n# Fix tokenizer parallelism warning\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\ndef check_dependencies():\n    \"\"\"Check and report on dependency versions - now more flexible\"\"\"\n    try:\n        import transformers\n        import torch\n        import sklearn\n        \n        print(\"=== DEPENDENCY CHECK ===\")\n        print(f\"✓ Transformers: {transformers.__version__}\")\n        print(f\"✓ PyTorch: {torch.__version__}\")\n        print(f\"✓ Scikit-learn: {sklearn.__version__}\")\n        \n        # Try to import datasets, but don't fail if version issues\n        try:\n            import datasets\n            print(f\"✓ Datasets: {datasets.__version__}\")\n        except ImportError:\n            print(\"⚠️  Datasets import issue - will try alternative approach\")\n        \n        # Check for CUDA availability\n        if torch.cuda.is_available():\n            print(f\"✓ CUDA available: {torch.cuda.get_device_name()}\")\n        else:\n            print(\"ℹ️  Using CPU (CUDA not available)\")\n            \n        print(\"=========================\\n\")\n        \n    except ImportError as e:\n        print(f\"❌ Critical dependency missing: {e}\")\n        print(\"Please install: pip install transformers torch scikit-learn\")\n        return False\n    \n    return True\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Create models directory\nos.makedirs('./models', exist_ok=True)\n\nclass IMDBDataset:\n    \"\"\"Custom dataset class for IMDB reviews\"\"\"\n    def __init__(self, texts, labels, tokenizer, max_length=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n        \n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\ndef load_and_prepare_data(file_path, subset_size=5000, test_size=0.2):\n    \"\"\"Load and prepare the IMDB dataset\"\"\"\n    print(\"Loading IMDB dataset...\")\n    df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n    \n    # Convert sentiment to numerical labels\n    df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n    \n    # Create subset for initial model comparison\n    subset_df = df.sample(n=subset_size, random_state=42)\n    \n    # Split the subset\n    train_texts, test_texts, train_labels, test_labels = train_test_split(\n        subset_df['review'].tolist(),\n        subset_df['label'].tolist(),\n        test_size=test_size,\n        random_state=42,\n        stratify=subset_df['label']\n    )\n    \n    return {\n        'full_df': df,\n        'subset': {\n            'train_texts': train_texts,\n            'test_texts': test_texts,\n            'train_labels': train_labels,\n            'test_labels': test_labels\n        }\n    }\n\ndef custom_f1_score(eval_pred):\n    \"\"\"Custom F1 score function for evaluation\"\"\"\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    f1 = f1_score(labels, predictions, average='weighted')\n    accuracy = accuracy_score(labels, predictions)\n    return {\n        'f1': f1,\n        'accuracy': accuracy\n    }\n\ndef create_hf_dataset(texts, labels, tokenizer, max_length=512):\n    \"\"\"Create dataset for training - with fallback approach\"\"\"\n    try:\n        # Try HuggingFace datasets first\n        from datasets import Dataset as HFDataset\n        \n        def tokenize_function(examples):\n            return tokenizer(\n                examples['text'],\n                truncation=True,\n                padding='max_length',\n                max_length=max_length\n            )\n        \n        dataset = HFDataset.from_dict({\n            'text': texts,\n            'labels': labels\n        })\n        \n        tokenized_dataset = dataset.map(tokenize_function, batched=True)\n        return tokenized_dataset\n        \n    except Exception as e:\n        print(f\"HF datasets failed: {e}, using fallback...\")\n    \n    # Fallback: Create a simple dataset class\n    print(\"Using fallback dataset approach...\")\n    \n    class SimpleDataset:\n        def __init__(self, texts, labels, tokenizer, max_length=512):\n            self.texts = texts\n            self.labels = labels\n            self.tokenizer = tokenizer\n            self.max_length = max_length\n            \n        def __len__(self):\n            return len(self.texts)\n            \n        def __getitem__(self, idx):\n            text = str(self.texts[idx])\n            label = self.labels[idx]\n            \n            encoding = self.tokenizer(\n                text,\n                truncation=True,\n                padding='max_length',\n                max_length=self.max_length,\n                return_tensors='pt'\n            )\n            \n            return {\n                'input_ids': encoding['input_ids'].flatten(),\n                'attention_mask': encoding['attention_mask'].flatten(),\n                'labels': torch.tensor(label, dtype=torch.long)\n            }\n    \n    return SimpleDataset(texts, labels, tokenizer, max_length)\n\ndef fine_tune_model(model_name, train_dataset, eval_dataset, output_dir, epochs=3):\n    \"\"\"Fine-tune a single model\"\"\"\n    print(f\"\\nFine-tuning {model_name}...\")\n    \n    try:\n        # Load tokenizer and model\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n        if tokenizer.pad_token is None:\n            tokenizer.pad_token = tokenizer.eos_token\n        \n        model = AutoModelForSequenceClassification.from_pretrained(\n            model_name,\n            num_labels=2,\n            ignore_mismatched_sizes=True\n        )\n        \n        # Check if CUDA is available\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        print(f\"Using device: {device}\")\n        \n        # Training arguments\n        training_args = TrainingArguments(\n            output_dir=output_dir,\n            num_train_epochs=epochs,\n            per_device_train_batch_size=8,  # Reduced for stability\n            per_device_eval_batch_size=16,  # Reduced for stability\n            warmup_steps=100,\n            weight_decay=0.01,\n            logging_dir=f'{output_dir}/logs',\n            logging_steps=50,\n            eval_strategy=\"epoch\",  # Fixed: was evaluation_strategy\n            save_strategy=\"epoch\",\n            load_best_model_at_end=True,\n            metric_for_best_model=\"f1\",\n            greater_is_better=True,\n            report_to=[],  # Fixed: use empty list instead of None\n            save_total_limit=2,\n            dataloader_pin_memory=False,  # Added for stability\n            remove_unused_columns=True,   # Added for efficiency\n            fp16=torch.cuda.is_available(),  # Use mixed precision if CUDA available\n            push_to_hub=False  # Explicitly disable hub pushing\n        )\n        \n        # Create trainer\n        trainer = Trainer(\n            model=model,\n            args=training_args,\n            train_dataset=train_dataset,\n            eval_dataset=eval_dataset,\n            compute_metrics=custom_f1_score,\n            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n        )\n        \n        print(f\"Starting training for {model_name}...\")\n        # Train the model\n        trainer.train()\n        print(f\"Training completed for {model_name}\")\n        \n        # Evaluate the model\n        print(f\"Evaluating {model_name}...\")\n        eval_results = trainer.evaluate()\n        \n        return {\n            'model': model,\n            'tokenizer': tokenizer,\n            'trainer': trainer,\n            'eval_results': eval_results\n        }\n        \n    except Exception as e:\n        print(f\"Error in fine_tune_model for {model_name}: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return None\n\ndef compare_models_on_subset(data_dict):\n    \"\"\"Compare 5 different models on the subset\"\"\"\n    # Model configurations - starting with lighter models first\n    models_to_test = {\n        'distilbert-base-uncased': 'DistilBERT',\n        'bert-base-uncased': 'BERT',\n        'roberta-base': 'RoBERTa',\n        'microsoft/deberta-v3-small': 'DeBERTa-v3-small',  # Using small version for faster testing\n        'google/electra-small-discriminator': 'ELECTRA-small'  # Using small version\n    }\n    \n    results = {}\n    \n    for model_name, display_name in models_to_test.items():\n        try:\n            print(f\"\\n{'='*50}\")\n            print(f\"Testing {display_name} ({model_name})\")\n            print(f\"{'='*50}\")\n            \n            # Load tokenizer\n            tokenizer = AutoTokenizer.from_pretrained(model_name)\n            if tokenizer.pad_token is None:\n                tokenizer.pad_token = tokenizer.eos_token\n            \n            # Create datasets\n            train_dataset = create_hf_dataset(\n                data_dict['subset']['train_texts'],\n                data_dict['subset']['train_labels'],\n                tokenizer\n            )\n            \n            eval_dataset = create_hf_dataset(\n                data_dict['subset']['test_texts'],\n                data_dict['subset']['test_labels'],\n                tokenizer\n            )\n            \n            # Fine-tune model\n            result = fine_tune_model(\n                model_name,\n                train_dataset,\n                eval_dataset,\n                f'./models/{display_name.lower().replace(\"-\", \"_\")}_subset',\n                epochs=1  # Further reduced epochs for initial comparison\n            )\n            \n            if result is None:\n                print(f\"Skipping {display_name} due to training failure\")\n                continue\n            \n            results[display_name] = {\n                'model_name': model_name,\n                'f1_score': result['eval_results']['eval_f1'],\n                'accuracy': result['eval_results']['eval_accuracy'],\n                'eval_loss': result['eval_results']['eval_loss'],\n                'model': result['model'],\n                'tokenizer': result['tokenizer']\n            }\n            \n            print(f\"{display_name} Results:\")\n            print(f\"F1 Score: {result['eval_results']['eval_f1']:.4f}\")\n            print(f\"Accuracy: {result['eval_results']['eval_accuracy']:.4f}\")\n            print(f\"Eval Loss: {result['eval_results']['eval_loss']:.4f}\")\n            \n        except Exception as e:\n            print(f\"Error training {display_name}: {str(e)}\")\n            continue\n    \n    return results\n\ndef plot_model_comparison(results):\n    \"\"\"Plot comparison of model performances\"\"\"\n    if not results:\n        print(\"No results to plot\")\n        return\n    \n    models = list(results.keys())\n    f1_scores = [results[model]['f1_score'] for model in models]\n    accuracies = [results[model]['accuracy'] for model in models]\n    \n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n    \n    # F1 Score comparison\n    bars1 = ax1.bar(models, f1_scores, color='skyblue', alpha=0.7)\n    ax1.set_title('Model Comparison - F1 Score', fontsize=14, fontweight='bold')\n    ax1.set_ylabel('F1 Score')\n    ax1.set_ylim(0, 1)\n    plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')\n    \n    # Add value labels on bars\n    for bar, score in zip(bars1, f1_scores):\n        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                f'{score:.3f}', ha='center', va='bottom')\n    \n    # Accuracy comparison\n    bars2 = ax2.bar(models, accuracies, color='lightcoral', alpha=0.7)\n    ax2.set_title('Model Comparison - Accuracy', fontsize=14, fontweight='bold')\n    ax2.set_ylabel('Accuracy')\n    ax2.set_ylim(0, 1)\n    plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')\n    \n    # Add value labels on bars\n    for bar, acc in zip(bars2, accuracies):\n        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n                f'{acc:.3f}', ha='center', va='bottom')\n    \n    plt.tight_layout()\n    plt.show()\n\ndef find_best_model(results):\n    \"\"\"Find the best performing model based on F1 score\"\"\"\n    if not results:\n        print(\"No results to evaluate\")\n        return None\n    \n    best_model_name = max(results.keys(), key=lambda k: results[k]['f1_score'])\n    best_result = results[best_model_name]\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"BEST MODEL: {best_model_name}\")\n    print(f\"{'='*60}\")\n    print(f\"Model Name: {best_result['model_name']}\")\n    print(f\"F1 Score: {best_result['f1_score']:.4f}\")\n    print(f\"Accuracy: {best_result['accuracy']:.4f}\")\n    print(f\"Eval Loss: {best_result['eval_loss']:.4f}\")\n    \n    return best_model_name, best_result\n\ndef fine_tune_on_full_dataset(best_model_info, full_df):\n    \"\"\"Fine-tune the best model on the full dataset\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(\"FINE-TUNING BEST MODEL ON FULL DATASET\")\n    print(f\"{'='*60}\")\n    \n    # Prepare full dataset\n    train_texts, test_texts, train_labels, test_labels = train_test_split(\n        full_df['review'].tolist(),\n        full_df['label'].tolist(),\n        test_size=0.1,  # Smaller test set for full dataset\n        random_state=42,\n        stratify=full_df['label']\n    )\n    \n    # Load tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(best_model_info['model_name'])\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n    \n    # Create datasets\n    train_dataset = create_hf_dataset(train_texts, train_labels, tokenizer)\n    eval_dataset = create_hf_dataset(test_texts, test_labels, tokenizer)\n    \n    # Fine-tune on full dataset\n    final_result = fine_tune_model(\n        best_model_info['model_name'],\n        train_dataset,\n        eval_dataset,\n        './models/best_model_full_dataset',\n        epochs=3\n    )\n    \n    print(f\"\\nFinal Model Results on Full Dataset:\")\n    print(f\"F1 Score: {final_result['eval_results']['eval_f1']:.4f}\")\n    print(f\"Accuracy: {final_result['eval_results']['eval_accuracy']:.4f}\")\n    print(f\"Eval Loss: {final_result['eval_results']['eval_loss']:.4f}\")\n    \n    return final_result, test_texts, test_labels\n\ndef run_inference_on_samples(model, tokenizer, test_texts, test_labels, num_samples=10):\n    \"\"\"Run inference on randomly sampled reviews\"\"\"\n    print(f\"\\n{'='*60}\")\n    print(\"INFERENCE ON RANDOM SAMPLES\")\n    print(f\"{'='*60}\")\n    \n    # Randomly sample reviews\n    indices = np.random.choice(len(test_texts), num_samples, replace=False)\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n    model.eval()\n    \n    sentiment_map = {0: 'Negative', 1: 'Positive'}\n    \n    with torch.no_grad():\n        for i, idx in enumerate(indices):\n            text = test_texts[idx]\n            true_label = test_labels[idx]\n            \n            # Tokenize\n            inputs = tokenizer(\n                text,\n                return_tensors='pt',\n                truncation=True,\n                padding=True,\n                max_length=512\n            )\n            \n            # Move to device\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n            \n            # Predict\n            outputs = model(**inputs)\n            logits = outputs.logits\n            predicted_label = torch.argmax(logits, dim=-1).cpu().numpy()[0]\n            confidence = torch.softmax(logits, dim=-1).max().cpu().numpy()\n            \n            # Display results\n            print(f\"\\n--- Sample {i+1} ---\")\n            print(f\"Review: {text[:200]}{'...' if len(text) > 200 else ''}\")\n            print(f\"True Sentiment: {sentiment_map[true_label]}\")\n            print(f\"Predicted Sentiment: {sentiment_map[predicted_label]}\")\n            print(f\"Confidence: {confidence:.4f}\")\n            print(f\"Correct: {'✓' if predicted_label == true_label else '✗'}\")\n\ndef main():\n    \"\"\"Main execution function\"\"\"\n    print(\"IMDB Sentiment Analysis Fine-tuning Pipeline\")\n    print(\"=\" * 60)\n    \n    # Check dependencies first\n    if not check_dependencies():\n        print(\"Please fix dependency issues before proceeding.\")\n        return\n    \n    # Load and prepare data\n    data_dict = load_and_prepare_data('IMDB Dataset.csv', subset_size=2000)  # Reduced subset for faster testing\n    print(f\"Full dataset size: {len(data_dict['full_df'])}\")\n    print(f\"Subset size for model comparison: {len(data_dict['subset']['train_texts']) + len(data_dict['subset']['test_texts'])}\")\n    \n    # Step 1: Compare 5 models on subset\n    print(f\"\\n{'='*60}\")\n    print(\"STEP 1: COMPARING 5 MODELS ON SUBSET\")\n    print(f\"{'='*60}\")\n    \n    results = compare_models_on_subset(data_dict)\n    \n    # Plot comparison\n    if results:\n        plot_model_comparison(results)\n        \n        # Find best model\n        best_model_name, best_model_info = find_best_model(results)\n        \n        if best_model_name:\n            # Step 2: Fine-tune best model on full dataset\n            print(f\"\\n{'='*60}\")\n            print(\"STEP 2: FINE-TUNING BEST MODEL ON FULL DATASET\")\n            print(f\"{'='*60}\")\n            \n            final_result, test_texts, test_labels = fine_tune_on_full_dataset(\n                best_model_info, data_dict['full_df']\n            )\n            \n            # Step 3: Run inference on samples\n            run_inference_on_samples(\n                final_result['model'],\n                final_result['tokenizer'],\n                test_texts,\n                test_labels,\n                num_samples=10\n            )\n            \n            print(f\"\\n{'='*60}\")\n            print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n            print(f\"{'='*60}\")\n            print(f\"Best Model: {best_model_name}\")\n            print(f\"Final F1 Score: {final_result['eval_results']['eval_f1']:.4f}\")\n            print(f\"Final Accuracy: {final_result['eval_results']['eval_accuracy']:.4f}\")\n    \n    else:\n        print(\"No models were successfully trained. Please check your setup and data.\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2025-09-07T05:03:53.665793Z","iopub.execute_input":"2025-09-07T05:03:53.666038Z","iopub.status.idle":"2025-09-07T05:13:40.611378Z","shell.execute_reply.started":"2025-09-07T05:03:53.666011Z","shell.execute_reply":"2025-09-07T05:13:40.609924Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-09-07 05:04:08.978998: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757221449.180533      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757221449.235887      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"IMDB Sentiment Analysis Fine-tuning Pipeline\n============================================================\n=== DEPENDENCY CHECK ===\n✓ Transformers: 4.52.4\n✓ PyTorch: 2.6.0+cu124\n✓ Scikit-learn: 1.2.2\n✓ Datasets: 3.6.0\n✓ CUDA available: Tesla P100-PCIE-16GB\n=========================\n\nLoading IMDB dataset...\nFull dataset size: 50000\nSubset size for model comparison: 2000\n\n============================================================\nSTEP 1: COMPARING 5 MODELS ON SUBSET\n============================================================\n\n==================================================\nTesting DistilBERT (distilbert-base-uncased)\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56cf3615926f4195a88f9f5c331c70f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df676c2b22b14af58929a93cece17c19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"455301c0778e4064858a886838ee095e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd31b145b87e4211a1b12e748df45ece"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be414e7c25724852b41db7b4e14623d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d709f1fb47c4c6992ff4cf4c3e3d3cb"}},"metadata":{}},{"name":"stdout","text":"\nFine-tuning distilbert-base-uncased...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ae62d1adf584b14b2c668b8741cf1c2"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nStarting training for distilbert-base-uncased...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 00:47, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.376900</td>\n      <td>0.325459</td>\n      <td>0.877470</td>\n      <td>0.877500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Training completed for distilbert-base-uncased\nEvaluating distilbert-base-uncased...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"DistilBERT Results:\nF1 Score: 0.8775\nAccuracy: 0.8775\nEval Loss: 0.3255\n\n==================================================\nTesting BERT (bert-base-uncased)\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62590da8595240b387baea7afa4c1203"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34dab36983a44d2085deb4076c58954d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"460173047d4e47ecb19be3209a88a58d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a8d392a805945c19ed4d56aa3234f00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6884566b87c4208b444c687e348178d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3a5eee5eb464bd3afcbd144e591acd7"}},"metadata":{}},{"name":"stdout","text":"\nFine-tuning bert-base-uncased...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58c08e529cc949f19411476c426a3bc7"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nStarting training for bert-base-uncased...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 01:31, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.341200</td>\n      <td>0.279987</td>\n      <td>0.902476</td>\n      <td>0.902500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Training completed for bert-base-uncased\nEvaluating bert-base-uncased...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"BERT Results:\nF1 Score: 0.9025\nAccuracy: 0.9025\nEval Loss: 0.2800\n\n==================================================\nTesting RoBERTa (roberta-base)\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ae4d61294c845f594cf31f425ee5765"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4637676cdc764df4ab909ca26c01ade4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0763327768274646bd776f78df01b9ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc56d1d343cf4df98a9ccbfd3967baaa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be24b4991ae24f75a8ef6cc77a4c5e39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eea3488fc2174217880108bb15459809"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfcc588efc304e2184cb742b837bbc01"}},"metadata":{}},{"name":"stdout","text":"\nFine-tuning roberta-base...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cd1a3dc7e5a4af7963c938bf5aee181"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nStarting training for roberta-base...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 01:32, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.392900</td>\n      <td>0.454240</td>\n      <td>0.884983</td>\n      <td>0.885000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Training completed for roberta-base\nEvaluating roberta-base...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 00:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"RoBERTa Results:\nF1 Score: 0.8850\nAccuracy: 0.8850\nEval Loss: 0.4542\n\n==================================================\nTesting DeBERTa-v3-small (microsoft/deberta-v3-small)\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"651ec0d49cb14631ba9296e2435fcb66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36c2130da9874bb29a95a56fcb6ff4d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f9826a1e838499d8e5bccd079ce88c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e2b6abff5684bbaa36f6e4b590fc93b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c3542a8189e4ad8a0743b2a868be75c"}},"metadata":{}},{"name":"stdout","text":"\nFine-tuning microsoft/deberta-v3-small...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48dcd2ef3a17455da8780c3c50c9ca12"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nStarting training for microsoft/deberta-v3-small...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/286M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b5f247b38a845b8a914a7574ff51924"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 01:14, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.315800</td>\n      <td>0.254354</td>\n      <td>0.907477</td>\n      <td>0.907500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Training completed for microsoft/deberta-v3-small\nEvaluating microsoft/deberta-v3-small...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"DeBERTa-v3-small Results:\nF1 Score: 0.9075\nAccuracy: 0.9075\nEval Loss: 0.2544\n\n==================================================\nTesting ELECTRA-small (google/electra-small-discriminator)\n==================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8338e135482f4d4d91d362fd550ed9f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"412ee5655c664cf1836c933fb68d7233"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36d5aa40a2f34daa948b563092f9d2f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"935b2cbc0f8a4574a28741b6773ddf0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e3882ff5969459b85489373787c9935"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/400 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40b93f6c031f467f8525bfb763ffea58"}},"metadata":{}},{"name":"stdout","text":"\nFine-tuning google/electra-small-discriminator...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/54.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77a95f73b0a64431971d0b519bee9608"}},"metadata":{}},{"name":"stderr","text":"Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nStarting training for google/electra-small-discriminator...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 00:24, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.475200</td>\n      <td>0.450544</td>\n      <td>0.834380</td>\n      <td>0.835000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/54.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfd593834d944c428503b000f7ba9d98"}},"metadata":{}},{"name":"stdout","text":"Training completed for google/electra-small-discriminator\nEvaluating google/electra-small-discriminator...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [25/25 00:01]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"ELECTRA-small Results:\nF1 Score: 0.8344\nAccuracy: 0.8350\nEval Loss: 0.4505\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x600 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n============================================================\nBEST MODEL: DeBERTa-v3-small\n============================================================\nModel Name: microsoft/deberta-v3-small\nF1 Score: 0.9075\nAccuracy: 0.9075\nEval Loss: 0.2544\n\n============================================================\nSTEP 2: FINE-TUNING BEST MODEL ON FULL DATASET\n============================================================\n\n============================================================\nFINE-TUNING BEST MODEL ON FULL DATASET\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/45000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba297102fa9b4a5db1e5c2d872c13661"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92f743a250c14623a15f15cc5d43f8f8"}},"metadata":{}},{"name":"stdout","text":"\nFine-tuning microsoft/deberta-v3-small...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nStarting training for microsoft/deberta-v3-small...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='265' max='16875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  265/16875 01:26 < 1:31:11, 3.04 it/s, Epoch 0.05/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3650529547.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/3650529547.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'='*60}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             final_result, test_texts, test_labels = fine_tune_on_full_dataset(\n\u001b[0m\u001b[1;32m    515\u001b[0m                 \u001b[0mbest_model_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_df'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             )\n","\u001b[0;32m/tmp/ipykernel_36/3650529547.py\u001b[0m in \u001b[0;36mfine_tune_on_full_dataset\u001b[0;34m(best_model_info, full_df)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;31m# Fine-tune on full dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m     final_result = fine_tune_model(\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0mbest_model_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3650529547.py\u001b[0m in \u001b[0;36mfine_tune_model\u001b[0;34m(model_name, train_dataset, eval_dataset, output_dir, epochs)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting training for {model_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training completed for {model_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2238\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2240\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2241\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m                     )\n\u001b[1;32m   2554\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2555\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3744\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3745\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3747\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3808\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3810\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3811\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m                     \u001b[0mlabel_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlabel_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}